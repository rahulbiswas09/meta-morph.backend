/**
 * This file was auto-generated by Fern from our API Definition.
 */
import * as environments from "../../../../environments";
import * as core from "../../../../core";
import * as ElevenLabs from "../../../index";
import { Transcripts } from "../resources/transcripts/client/Client";
export declare namespace SpeechToText {
    interface Options {
        environment?: core.Supplier<environments.ElevenLabsEnvironment | string>;
        /** Specify a custom URL to connect the client to. */
        baseUrl?: core.Supplier<string>;
        /** Override the xi-api-key header */
        apiKey?: core.Supplier<string | undefined>;
        /** Additional headers to include in requests. */
        headers?: Record<string, string | core.Supplier<string | undefined> | undefined>;
    }
    interface RequestOptions {
        /** The maximum time to wait for a response in seconds. */
        timeoutInSeconds?: number;
        /** The number of times to retry the request. Defaults to 2. */
        maxRetries?: number;
        /** A hook to abort the request. */
        abortSignal?: AbortSignal;
        /** Override the xi-api-key header */
        apiKey?: string | undefined;
        /** Additional headers to include in the request. */
        headers?: Record<string, string | core.Supplier<string | undefined> | undefined>;
    }
}
export declare class SpeechToText {
    protected readonly _options: SpeechToText.Options;
    protected _transcripts: Transcripts | undefined;
    constructor(_options?: SpeechToText.Options);
    get transcripts(): Transcripts;
    /**
     * Transcribe an audio or video file. If webhook is set to true, the request will be processed asynchronously and results sent to configured webhooks. When use_multi_channel is true and the provided audio has multiple channels, a 'transcripts' object with separate transcripts for each channel is returned. Otherwise, returns a single transcript. The optional webhook_metadata parameter allows you to attach custom data that will be included in webhook responses for request correlation and tracking.
     *
     * @param {ElevenLabs.BodySpeechToTextV1SpeechToTextPost} request
     * @param {SpeechToText.RequestOptions} requestOptions - Request-specific configuration.
     *
     * @throws {@link ElevenLabs.UnprocessableEntityError}
     *
     * @example
     *     await client.speechToText.convert({
     *         modelId: "model_id"
     *     })
     */
    convert(request: ElevenLabs.BodySpeechToTextV1SpeechToTextPost, requestOptions?: SpeechToText.RequestOptions): core.HttpResponsePromise<ElevenLabs.SpeechToTextConvertResponse>;
    private __convert;
}
